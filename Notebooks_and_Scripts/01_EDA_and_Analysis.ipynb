{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import lightgbm as lgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "import optuna\n",
    "import gc\n",
    "import warnings\n",
    "import traceback\n",
    "from collections import defaultdict\n",
    "import math\n",
    "\n",
    "# Import helper functions\n",
    "from utils import (\n",
    "    smape,\n",
    "    deg_to_sin,\n",
    "    deg_to_cos,\n",
    "    sincos_to_deg,\n",
    "    convert_units,\n",
    "    create_geo_clusters,\n",
    "    create_time_features,\n",
    "    create_lag_rolling_features_advanced,\n",
    "    select_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 02_model_training.ipynb\n",
    "\n",
    "# ==============================================================================\n",
    "# Imports\n",
    "# ==============================================================================\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# Configuration\n",
    "# ==============================================================================\n",
    "# --- Suppress Warnings ---\n",
    "warnings.filterwarnings(\"ignore\", category=optuna.exceptions.ExperimentalWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# --- Reproducibility & Control ---\n",
    "GLOBAL_SEED = 42\n",
    "np.random.seed(GLOBAL_SEED)\n",
    "N_SEEDS = 3\n",
    "OPTUNA_TRIALS = 100\n",
    "N_SPLITS_TSCV = 5\n",
    "N_SPLITS_FEAT_SELECT = 5\n",
    "TOP_N_FEATURES = 150\n",
    "\n",
    "# --- Data & Targets ---\n",
    "TARGET_COLS = [\"Avg_Temperature\", \"Radiation\", \"Rain_Amount\", \"Wind_Speed\", \"Wind_Direction\"]\n",
    "TARGETS_NORMAL = [\"Avg_Temperature\", \"Radiation\", \"Rain_Amount\", \"Wind_Speed\"]\n",
    "TARGET_WIND_DIR = \"Wind_Direction\"\n",
    "LOG_TRANSFORM_TARGETS = [\"Rain_Amount\", \"Radiation\", \"Wind_Speed\"]\n",
    "\n",
    "# --- Feature Engineering ---\n",
    "KELVIN_THRESHOLD = 100\n",
    "N_CLUSTERS = 10\n",
    "LAG_ROLL_INPUT_COLS = [\n",
    "    \"Avg_Temperature\",\n",
    "    \"Avg_Feels_Like_Temperature\",\n",
    "    \"Radiation\",\n",
    "    \"Rain_Amount\",\n",
    "    \"Rain_Duration\",\n",
    "    \"Wind_Speed\",\n",
    "    \"Temperature_Range\",\n",
    "    \"Feels_Like_Temperature_Range\",\n",
    "    \"Evapotranspiration\"\n",
    "]\n",
    "CATEGORICAL_FEATURES_BASE = ['kingdom', 'geo_cluster', 'month', 'dayofweek', 'year', 'quarter']\n",
    "\n",
    "# ==============================================================================\n",
    "# Main Execution\n",
    "# ==============================================================================\n",
    "# --- Load Data ---\n",
    "print(\"Loading initial data...\")\n",
    "try:\n",
    "    train_df_orig = pd.read_csv(\"train.csv\")\n",
    "    test_df_orig = pd.read_csv(\"test.csv\")\n",
    "    sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error loading data: {e}. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "if train_df_orig.empty or test_df_orig.empty:\n",
    "    print(\"Error: Input CSV is empty. Exiting.\")\n",
    "    exit()\n",
    "\n",
    "oof_preds_all_seeds = {}\n",
    "test_preds_all_seeds = defaultdict(list)\n",
    "\n",
    "for seed_run in range(N_SEEDS):\n",
    "    current_seed = GLOBAL_SEED + seed_run\n",
    "    print(f\"\\n{'='*25} Running Seed {seed_run+1}/{N_SEEDS} (Seed: {current_seed}) {'='*25}\")\n",
    "    np.random.seed(current_seed)\n",
    "    optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    \n",
    "    # --- Reload and Preprocess Data ---\n",
    "    train_df = train_df_orig.copy()\n",
    "    test_df = test_df_orig.copy()\n",
    "    \n",
    "    train_df = convert_units(train_df)\n",
    "    train_df, test_df = create_geo_clusters(train_df, test_df, N_CLUSTERS, current_seed)\n",
    "    train_df = create_time_features(train_df)\n",
    "    test_df = create_time_features(test_df)\n",
    "    \n",
    "    if train_df.empty or test_df.empty:\n",
    "        print(f\"DF empty after time features. Skipping seed {current_seed}.\")\n",
    "        continue\n",
    "\n",
    "    # Wind Dir Handling\n",
    "    train_df[f'{TARGET_WIND_DIR}_sin'] = deg_to_sin(train_df[TARGET_WIND_DIR])\n",
    "    train_df[f'{TARGET_WIND_DIR}_cos'] = deg_to_cos(train_df[TARGET_WIND_DIR])\n",
    "    targets_with_sincos = TARGETS_NORMAL + [f'{TARGET_WIND_DIR}_sin', f'{TARGET_WIND_DIR}_cos']\n",
    "\n",
    "    # Advanced Features\n",
    "    lag_roll_inputs_this_run = [c for c in LAG_ROLL_INPUT_COLS if c in train_df.columns]\n",
    "    train_df = create_lag_rolling_features_advanced(train_df, lag_roll_inputs_this_run)\n",
    "    test_df = create_lag_rolling_features_advanced(test_df, lag_roll_inputs_this_run)\n",
    "\n",
    "    # --- Define Full Feature Set ---\n",
    "    exclude_cols = TARGET_COLS + targets_with_sincos + ['ID', 'date', 'latitude', 'longitude']\n",
    "    initial_features = [f for f in train_df.columns if f not in exclude_cols and f in test_df.columns]\n",
    "    categorical_features = [f for f in CATEGORICAL_FEATURES_BASE if f in initial_features]\n",
    "\n",
    "    # Align Categoricals\n",
    "    for cat_col in categorical_features:\n",
    "        all_cats = pd.concat([train_df[cat_col].astype(str), test_df[cat_col].astype(str)]).unique()\n",
    "        train_df[cat_col] = pd.Categorical(train_df[cat_col].astype(str), categories=all_cats)\n",
    "        test_df[cat_col] = pd.Categorical(test_df[cat_col].astype(str), categories=all_cats)\n",
    "\n",
    "    # --- Data for Modeling ---\n",
    "    try:\n",
    "        X = train_df[initial_features].copy()\n",
    "        Y = train_df[targets_with_sincos].copy()\n",
    "        X_test_full = test_df[initial_features].copy()\n",
    "    except KeyError as e:\n",
    "        print(f\"Error preparing data arrays: Missing columns {e}. Skipping seed.\")\n",
    "        continue\n",
    "\n",
    "    oof_df_seed = pd.DataFrame(index=X.index, columns=targets_with_sincos)\n",
    "\n",
    "    for target in targets_with_sincos:\n",
    "        print(f\"\\n===== Processing Target: {target} (Seed: {current_seed}) =====\")\n",
    "        gc.collect()\n",
    "        y_target = Y[target].copy()\n",
    "        X_target = X.copy()\n",
    "        \n",
    "        if y_target.isnull().any():\n",
    "            valid_indices = y_target.notna()\n",
    "            X_target = X_target.loc[valid_indices]\n",
    "            y_target = y_target.loc[valid_indices]\n",
    "            if X_target.empty:\n",
    "                print(\"  No data left. Skipping.\")\n",
    "                continue\n",
    "\n",
    "        # Target Transformation\n",
    "        is_log_transformed = False\n",
    "        inv_tf = lambda x: x\n",
    "        if target in LOG_TRANSFORM_TARGETS:\n",
    "            y_target_transformed = np.log1p(y_target + 1e-6) if (y_target <= 0).any() else np.log1p(y_target)\n",
    "            inv_tf = np.expm1\n",
    "            is_log_transformed = True\n",
    "\n",
    "        # Feature Selection\n",
    "        selected_features = select_features(X_target, y_target_transformed, initial_features, TOP_N_FEATURES, categorical_features, current_seed)\n",
    "        X_train_fs = X_target[selected_features]\n",
    "        X_test_fs = X_test_full[selected_features].copy()\n",
    "\n",
    "        # Imputation & Scaling\n",
    "        numerical_features_selected = X_train_fs.select_dtypes(include=np.number).columns.tolist()\n",
    "        if numerical_features_selected:\n",
    "            imputer = SimpleImputer(strategy='median')\n",
    "            X_train_fs[numerical_features_selected] = imputer.fit_transform(X_train_fs[numerical_features_selected])\n",
    "            X_test_fs[numerical_features_selected] = imputer.transform(X_test_fs[numerical_features_selected])\n",
    "            \n",
    "            scaler = StandardScaler()\n",
    "            X_train_fs[numerical_features_selected] = scaler.fit_transform(X_train_fs[numerical_features_selected])\n",
    "            X_test_fs[numerical_features_selected] = scaler.transform(X_test_fs[numerical_features_selected])\n",
    "\n",
    "        cats_selected = [c for c in categorical_features if c in selected_features]\n",
    "        for cat_col in cats_selected:\n",
    "            all_cats = pd.concat([X_train_fs[cat_col].astype(str), X_test_fs[cat_col].astype(str)]).unique()\n",
    "            X_train_fs[cat_col] = pd.Categorical(X_train_fs[cat_col].astype(str), categories=all_cats)\n",
    "            X_test_fs[cat_col] = pd.Categorical(X_test_fs[cat_col].astype(str), categories=all_cats)\n",
    "\n",
    "        # Optuna Tuning\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'objective': 'regression_l1',\n",
    "                'metric': 'mae',\n",
    "                'verbosity': -1,\n",
    "                'n_jobs': -1,\n",
    "                'seed': current_seed,\n",
    "                'boosting_type': 'gbdt',\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 500, 4000, step=100),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.005, 0.05),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
    "                'max_depth': trial.suggest_int('max_depth', 5, 16),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0, step=0.05),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0, step=0.05),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n",
    "                'subsample_freq': trial.suggest_int('subsample_freq', 0, 7),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 5, 50)\n",
    "            }\n",
    "            \n",
    "            tscv = TimeSeriesSplit(n_splits=N_SPLITS_TSCV)\n",
    "            scores = []\n",
    "            oof_preds_fold = np.full(len(X_train_fs), np.nan)\n",
    "            lgbm_cats_obj = [c for c in cats_selected if c in X_train_fs.columns] or 'auto'\n",
    "\n",
    "            for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train_fs)):\n",
    "                X_tr, X_val = X_train_fs.iloc[train_idx], X_train_fs.iloc[val_idx]\n",
    "                y_tr, y_val = y_target_transformed.iloc[train_idx], y_target_transformed.iloc[val_idx]\n",
    "                y_val_orig = y_target.iloc[val_idx]\n",
    "\n",
    "                model = LGBMRegressor(**params)\n",
    "                callbacks = [lgbm.early_stopping(100, verbose=False)]\n",
    "                if OPTUNA_INTEGRATION_AVAILABLE:\n",
    "                    callbacks.append(lgb_optuna.LightGBMPruningCallback(trial, 'l1'))\n",
    "\n",
    "                model.fit(\n",
    "                    X_tr, y_tr,\n",
    "                    eval_set=[(X_val, y_val)],\n",
    "                    eval_metric='mae',\n",
    "                    callbacks=callbacks,\n",
    "                    categorical_feature=lgbm_cats_obj\n",
    "                )\n",
    "\n",
    "                preds_val_tf = model.predict(X_val)\n",
    "                preds_val_orig = inv_tf(preds_val_tf)\n",
    "                oof_preds_fold[val_idx] = preds_val_orig\n",
    "\n",
    "                if target in LOG_TRANSFORM_TARGETS or target == \"Radiation\":\n",
    "                    preds_val_orig = np.clip(preds_val_orig, 0, None)\n",
    "                if target.endswith('_sin') or target.endswith('_cos'):\n",
    "                    preds_val_orig = np.clip(preds_val_orig, -1, 1)\n",
    "\n",
    "                scores.append(smape(y_val_orig, preds_val_orig))\n",
    "\n",
    "            trial.set_user_attr(\"oof_predictions\", oof_preds_fold)\n",
    "            return np.mean(scores)\n",
    "\n",
    "        pruner = optuna.pruners.MedianPruner(n_startup_trials=15, n_warmup_steps=30, interval_steps=10)\n",
    "        study = optuna.create_study(direction='minimize', pruner=pruner)\n",
    "        study.optimize(objective, n_trials=OPTUNA_TRIALS, show_progress_bar=True, catch=(Exception,))\n",
    "\n",
    "        # Store best OOF\n",
    "        best_oof = study.best_trial.user_attrs.get(\"oof_predictions\")\n",
    "        if best_oof is not None:\n",
    "            valid_indices = ~np.isnan(best_oof)\n",
    "            oof_df_seed.loc[X_target.index[valid_indices], target] = best_oof[valid_indices]\n",
    "\n",
    "        # Train Final Model\n",
    "        final_params = study.best_trial.params\n",
    "        final_params.update({\n",
    "            'objective': 'regression_l1',\n",
    "            'metric': 'mae',\n",
    "            'verbosity': -1,\n",
    "            'n_jobs': -1,\n",
    "            'seed': current_seed,\n",
    "            'boosting_type': 'gbdt'\n",
    "        })\n",
    "        final_model = LGBMRegressor(**final_params)\n",
    "        final_model.fit(X_train_fs, y_target_transformed, categorical_feature=lgbm_cats_obj)\n",
    "\n",
    "        # Predict Test\n",
    "        test_preds_tf = final_model.predict(X_test_fs)\n",
    "        test_preds_orig = inv_tf(test_preds_tf)\n",
    "        test_preds_all_seeds[target].append(test_preds_orig)\n",
    "\n",
    "        del final_model, study, X_target, y_target, X_train_fs, X_test_fs\n",
    "        gc.collect()\n",
    "\n",
    "    oof_preds_all_seeds[current_seed] = oof_df_seed\n",
    "\n",
    "# ==============================================================================\n",
    "# Aggregation & Final Submission\n",
    "# ==============================================================================\n",
    "print(\"\\n{'='*25} Ensembling & Final Submission {'='*25}\")\n",
    "final_test_preds_agg = {}\n",
    "expected_len = len(test_df_orig)\n",
    "\n",
    "for target in test_preds_all_seeds.keys():\n",
    "    valid_preds = [p for p in test_preds_all_seeds[target] if len(p) == expected_len]\n",
    "    final_test_preds_agg[target] = np.mean(valid_preds, axis=0) if valid_preds else np.zeros(expected_len)\n",
    "\n",
    "# Convert Wind Dir\n",
    "wind_dir = sincos_to_deg(\n",
    "    np.clip(final_test_preds_agg.get(f'{TARGET_WIND_DIR}_sin', 0), -1, 1),\n",
    "    np.clip(final_test_preds_agg.get(f'{TARGET_WIND_DIR}_cos', 0), -1, 1)\n",
    ")\n",
    "final_test_preds_agg[TARGET_WIND_DIR] = wind_dir\n",
    "\n",
    "# Post-process\n",
    "for target in TARGET_COLS:\n",
    "    if target in final_test_preds_agg:\n",
    "        preds = final_test_preds_agg[target]\n",
    "        if target in [\"Rain_Amount\", \"Radiation\", \"Wind_Speed\"]:\n",
    "            preds = np.clip(preds, 0, None)\n",
    "            preds[preds < 1e-4] = 0\n",
    "        if target == TARGET_WIND_DIR:\n",
    "            preds = np.clip(preds, 0, 360)\n",
    "        if target == \"Avg_Temperature\":\n",
    "            preds = np.clip(preds, -50, 60)\n",
    "        final_test_preds_agg[target] = preds\n",
    "    else:\n",
    "        final_test_preds_agg[target] = 0\n",
    "\n",
    "# Create Submission\n",
    "submission_df = pd.DataFrame({'ID': test_df_orig['ID']})\n",
    "for col in TARGET_COLS:\n",
    "    submission_df[col] = final_test_preds_agg.get(col, 0)\n",
    "\n",
    "final_submission = sample_submission[['ID']].merge(submission_df, on='ID', how='left')\n",
    "final_submission = final_submission.fillna(0)[sample_submission.columns]\n",
    "final_submission.to_csv(\"final_submission.csv\", index=False)\n",
    "print(\"Submission file created successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
